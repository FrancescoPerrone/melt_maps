{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "import hyperspy.api as hs\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA, NMF, FactorAnalysis\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from skcmeans.algorithms import Probabilistic\n",
    "from skcmeans.algorithms import Probabilistic, Possibilistic, GustafsonKesselMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the hdf5 data from Sigray HHDF5 standard to Hyperspy standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: /Users/joshuashea/data\n",
      "ls: /Users/joshuashea/data: No such file or directory\n",
      "/Users/user/Documents/github/melt_maps\n"
     ]
    }
   ],
   "source": [
    "!cd '/Users/joshuashea/data'\n",
    "!ls '/Users/joshuashea/data'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5printR(item, leading = ''):\n",
    "    for key in item:\n",
    "        if isinstance(item[key], h5py.Dataset):\n",
    "            print(leading + key + ': ' + str(item[key].shape))\n",
    "        else:\n",
    "            print(leading + key)\n",
    "            h5printR(item[key], leading + '  ')\n",
    "\n",
    "# Print structure of a `.h5` file            \n",
    "def h5print(filename):\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        print(filename)\n",
    "        h5printR(h, '  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'joshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xrf_data \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjoshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/xraylarch/lib/python3.9/site-packages/h5py/_hl/files.py:507\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[1;32m    502\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    503\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    504\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    505\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    506\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 507\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/xraylarch/lib/python3.9/site-packages/h5py/_hl/files.py:220\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    219\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 220\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    222\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'joshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "xrf_data = h5py.File('/Users/joshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5','r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5\n",
      "  xrmmap\n",
      "    areas\n",
      "    config\n",
      "      environ\n",
      "        address: (65,)\n",
      "        name: (65,)\n",
      "        value: (65,)\n",
      "      general\n",
      "        basedir: ()\n",
      "        envfile: ()\n",
      "      mca_calib\n",
      "        offset: (7,)\n",
      "        quad: (7,)\n",
      "        slope: (7,)\n",
      "      mca_settings\n",
      "      motor_controller\n",
      "        group: ()\n",
      "        host: ()\n",
      "        mode: ()\n",
      "        passwd: ()\n",
      "        positioners: ()\n",
      "        type: ()\n",
      "        user: ()\n",
      "      notes\n",
      "      positioners\n",
      "        13IDE:En:Energy: ()\n",
      "        13IDE:m19: ()\n",
      "        13IDE:m25: ()\n",
      "        13IDE:m28: ()\n",
      "        13IDE:m31: ()\n",
      "        13IDE:m32: ()\n",
      "        13IDE:m34: ()\n",
      "        13IDE:m35: ()\n",
      "        13IDE:m36: ()\n",
      "        13IDE:m39: ()\n",
      "        13IDE:m4: ()\n",
      "        13IDE:m40: ()\n",
      "        13IDE:userTran5.A: ()\n",
      "        13XRM:ANA:Energy: ()\n",
      "        13XRM:m1: ()\n",
      "        13XRM:m10: ()\n",
      "        13XRM:m11: ()\n",
      "        13XRM:m2: ()\n",
      "        13XRM:m3: ()\n",
      "        13XRM:m4: ()\n",
      "        13XRM:m5: ()\n",
      "        13XRM:m6: ()\n",
      "      rois\n",
      "        address: (35,)\n",
      "        limits: (35, 7, 2)\n",
      "        name: (35,)\n",
      "      scan\n",
      "        comments: ()\n",
      "        dimension: ()\n",
      "        filename: ()\n",
      "        pos1: ()\n",
      "        pos2: ()\n",
      "        start1: ()\n",
      "        start2: ()\n",
      "        step1: ()\n",
      "        step2: ()\n",
      "        stop1: ()\n",
      "        stop2: ()\n",
      "        text: ()\n",
      "        time1: ()\n",
      "    mcasum\n",
      "      counts: (201, 201, 4096)\n",
      "      dtfactor: (201, 201)\n",
      "      energy: (4096,)\n",
      "      inpcounts: (201, 201)\n",
      "      livetime: (201, 201)\n",
      "      outcounts: (201, 201)\n",
      "      realtime: (201, 201)\n",
      "    positions\n",
      "      address: (4,)\n",
      "      name: (4,)\n",
      "      pos: (201, 201, 4)\n",
      "    roimap\n",
      "      det_address: (253,)\n",
      "      det_cor: (201, 201, 253)\n",
      "      det_name: (253,)\n",
      "      det_raw: (201, 201, 253)\n",
      "      mcasum\n",
      "        As Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ba La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Br Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ca Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ce La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cl Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Co Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cu Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Eu La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Fe Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ge Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        I La1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        I Lb1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        K Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Mn Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Mo Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ni Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        OutputCounts\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        P Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Pb La1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Rb Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Re La1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        S Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Sc Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Se Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Si Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Sr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ti Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        V Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        V Kb\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Y Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zn Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zr L\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "      sum_cor: (201, 201, 43)\n",
      "      sum_list: (43, 7)\n",
      "      sum_name: (43,)\n",
      "      sum_raw: (201, 201, 43)\n",
      "    scalars\n",
      "      I0: (201, 201)\n",
      "      I0_raw: (201, 201)\n",
      "      I1: (201, 201)\n",
      "      I1_raw: (201, 201)\n",
      "      I2: (201, 201)\n",
      "      I2_raw: (201, 201)\n",
      "      TSCALER: (201, 201)\n",
      "      TSCALER_raw: (201, 201)\n",
      "    work\n",
      "    xrd1d\n"
     ]
    }
   ],
   "source": [
    "h5print('/Users/joshuashea/data/ISE_500sqaures_A21-016_Map1_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1=xrf_data['xrmmap/mcasum/counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 4096)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_1[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the attributes associated with the data. \n",
    "\n",
    "these are needed to scale the data correctly etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in xrf_data['xrmmap/mcasum/counts'].attrs:\n",
    "    print(att,xrf_data['xrmmap/mcasum/counts'].attrs[att])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical paramters \n",
    "\n",
    "need these t ocorrectly scale the pixels and arrange the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_x, iterations, num_ch = xrf_data['entry']['data']['data'].shape\n",
    "\n",
    "print(pix_x, iterations, num_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pix_x_size=xrf_data['entry']['data']['data'].attrs['ScanXWidth']/pix_x\n",
    "\n",
    "#pix_y_size=np.abs(xrf_data['entry']['data']['data'].attrs['ScanXWidth'].attrs['ScanYWidth'])/(corr_data['entry']['detector']['data1'].attrs['ScanYNumberOfPoints']-1)\n",
    "#print(pix_x_size,pix_y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map = hs.signals.Signal1D(xrf_data['entry']['data']['data'])\n",
    "xrf_map.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map=xrf_map.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is the file conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map = hs.signals.Signal1D(xrf_data['entry']['data']['data'])\n",
    "xrf_map=xrf_map.sum(axis=0)\n",
    "print(xrf_map)\n",
    "print(xrf_map.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_path='/media/2TB_NVMe_2/science_2/2022_XRF_melts/data/ISE_500sq_A21-016_map2_002_hspy/'\n",
    "\n",
    "#this changes the sigray file to a hyperspy... proably should delete these once we have stacked.\n",
    "for fname in glob.glob('/media/2TB_NVMe_2/science_2/2022_XRF_melts/data/ISE_500sqaures_A21-016_Map2_002_rawmap/xsp3.*'):\n",
    "\n",
    "    print(fname)\n",
    "    map=int(fname.split('xsp3.')[1])\n",
    "    xrf_data = h5py.File(fname,'r' )\n",
    "    xrf_map = hs.signals.Signal1D(xrf_data['entry']['data']['data'])\n",
    "#sum the 'y- axis' as realised we ahave two passes per pixel, so intigrate    \n",
    "    xrf_map=xrf_map.sum(axis=0)\n",
    "    xrf_map.crop(axis=0,start=1)\n",
    "    if (map%2) == 0: xrf_map.data=np.flip(xrf_map.data, axis=0)\n",
    "    \n",
    "    #xrf_map.axes_manager[0].name = 'X'\n",
    "    #xrf_map.axes_manager['X'].units = 'mm'\n",
    "    #xrf_map.axes_manager['X'].scale = pix_x_size\n",
    "    #xrf_map.axes_manager['X'].offset = corr_data['entry']['detector']['data1'].attrs['MotorXLineStartRBV']\n",
    "\n",
    "    #xrf_map.axes_manager[1].name = 'Y'\n",
    "    #xrf_map.axes_manager['Y'].units = 'mm'\n",
    "    #xrf_map.axes_manager['Y'].scale = pix_y_size\n",
    "    #xrf_map.axes_manager['Y'].offset = corr_data['entry']['detector']['data1'].attrs['MotorYLineStartRBV']\n",
    "\n",
    "\n",
    "    #xrf_map.axes_manager[1].name= 'Energy'\n",
    "    #xrf_map.axes_manager['Energy'].units = 'kev'\n",
    "    #xrf_map.axes_manager['Energy'].scale = corr_data['entry']['detector']['data1'].attrs['ECAL'][1]\n",
    "    #xrf_map.axes_manager['Energy'].offset = corr_data['entry']['detector']['data1'].attrs['ECAL'][0]\n",
    "\n",
    "    #print(xrf_map.axes_manager)\n",
    " \n",
    "    \n",
    "    print(map)\n",
    "    xrf_map.save(save_path+'at16_map2_002_{:05d}'.format(map))\n",
    "#################################################################################\n",
    "    \n",
    "xrf_stack=hs.load(save_path+'at16_map2_002_*.hspy',stack=True)\n",
    "\n",
    "#xrf_stack.axes_manager[1].name = 'Y'\n",
    "#xrf_stack.axes_manager['Y'].units = 'mm'\n",
    "#xrf_stack.axes_manager['Y'].scale = pix_y_size\n",
    "#xrf_stack.axes_manager['Y'].offset = corr_data['entry']['detector']['data1'].attrs['MotorYLineStartRBV']\n",
    "\n",
    "print(xrf_stack.axes_manager)\n",
    "\n",
    "#be good to have dialoge etc for the file name but this works....\n",
    "\n",
    "xrf_stack.save(save_path+'at16_map2_002_mapped')\n",
    "\n",
    "xrf_stack.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick data inspection.\n",
    "\n",
    "ran PCA to see what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack=hs.load(save_path+'at16_map2_002_*.hspy',stack=True)\n",
    "\n",
    "#xrf_stack.axes_manager[1].name = 'Y'\n",
    "#xrf_stack.axes_manager['Y'].units = 'mm'\n",
    "#xrf_stack.axes_manager['Y'].scale = pix_y_size\n",
    "#xrf_stack.axes_manager['Y'].offset = corr_data['entry']['detector']['data1'].attrs['MotorYLineStartRBV']\n",
    "\n",
    "print(xrf_stack.axes_manager)\n",
    "\n",
    "#be good to have dialoge etc for the file name but this works....\n",
    "xrf_stack.change_dtype('float32')\n",
    "\n",
    "xrf_stack.save(save_path+'at16_map2_002_mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.change_dtype('float32')\n",
    "\n",
    "\n",
    "xrf_stack.save(save_path+'at16_map2_002_mapped_crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm='SVD', output_dimension=20)\n",
    "\n",
    "xrf_stack.plot_explained_variance_ratio(log=True, vline=True)\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.plot_cumulative_explained_variance_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note** iterative cropping above showed that most data/ analysis was better when cropping down to the shape (157, 63|2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.save(save_path+'lisheen_low_res_map_data_Crop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-explore\n",
    "\n",
    "get 6 good factors... need to label peaks etc but starting to pull out data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm='NMF', output_dimension=6)\n",
    "\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm='NMF', output_dimension=5)\n",
    "\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examine with factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"FA\", FactorAnalysis(n_components=10,rotation = 'varimax'))])\n",
    "\n",
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm=pipeline, return_info=True,output_dimension=11)\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_load= xrf_stack.get_decomposition_loadings()\n",
    "#fa_load.save('snv_eds_analysis/plage_TD_eds_FA_4_load')\n",
    "\n",
    "fa_fact= xrf_stack.get_decomposition_factors()\n",
    "#fa_fact.set_elements(elements)\n",
    "\n",
    "\n",
    "#fa_fact.save('snv_eds_analysis/plage_TD_eds_FA_4_fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_facts, ydim,xdim=fa_load.data.shape\n",
    "\n",
    "fact_load_vect= pd.DataFrame((fa_load.data.reshape(fa_facts, ydim*xdim).T), columns = ['Factor 1','Factor 2','Factor 3','Factor 4', 'Factor 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_load_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_facts, ydim,xdim=fa_load.data.shape\n",
    "fa_vect=fa_load.data.reshape(fa_facts,ydim*xdim).transpose()\n",
    "fa_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_to_cluster=fa_vect[:,:fa_facts]\n",
    "loadings_to_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGK(Probabilistic, GustafsonKesselMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clus=10\n",
    "pgk = PGK(n_clusters =num_clus, n_init=10).fit(loadings_to_cluster)\n",
    "# Process results for visualisation\n",
    "print(pgk.memberships_)\n",
    "labels_ = np.argmax(pgk.memberships_, axis=1)\n",
    "memberships_ = pgk.memberships_[range(len(pgk.memberships_)), labels_] \n",
    "\n",
    "labels = labels_.reshape([ydim,xdim])\n",
    "labels=hs.signals.Signal2D(labels)\n",
    "labels.plot(cmap='tab10')\n",
    "\n",
    "mems=pgk.memberships_.reshape(ydim,xdim,num_clus)\n",
    "print(mems.shape)\n",
    "\n",
    "mem_maps=hs.signals.Signal2D(mems)\n",
    "mem_maps=mem_maps.transpose(signal_axes=(2,0))\n",
    "mem_maps.change_dtype('float32')\n",
    "mem_maps.plot(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "mem_maps.plot(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next steps\n",
    "\n",
    "1. makes sense to calcualte an elbow test or examine the BIC to determine the 'optimal' number of clusters\n",
    "2. explore applying HDBSCAN on the FA/ PCA factors\n",
    "3. would also to explore the UMAP pretreatment then HDBSCAN\n",
    "4. maybe blind source separation (ie ICA) after PCA.\n",
    "\n",
    "for 2 and 3 need a different virtual enviroment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actually lets try ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm='SVD', output_dimension=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.blind_source_separation(number_of_components=7)\n",
    "\n",
    "xrf_stack.plot_bss_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
