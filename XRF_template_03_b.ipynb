{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "\n",
    "# handling XRF data and datatypes\n",
    "import h5py # interface to HDF5 data format and allows manipulation using numpy\n",
    "import hyperspy.api as hs # data analysis of multidimensional datasets for analytical procedure\n",
    "\n",
    "#Dimension reduction and clustering\n",
    "import umap\n",
    "import hdbscan\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.cluster as cluster\n",
    "# from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert XRF data to Hyperspy standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mISE_500sqaures_A21-016_Map1_001.h5\u001b[m\u001b[m\n",
      "\u001b[31mISE_500sqaures_A21_054_botom_right_map_center_001.h5\u001b[m\u001b[m\n",
      "map.hspy\n",
      "map1.hspy\n",
      "/Users/user/Documents/GitHub/melt_maps\n"
     ]
    }
   ],
   "source": [
    "!cd '/Users/user/Documents/Projects/XRF_machine_learning/data'\n",
    "!ls '/Users/user/Documents/Projects/XRF_machine_learning/data'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5printR(item, leading = ''):\n",
    "    for key in item:\n",
    "        if isinstance(item[key], h5py.Dataset):\n",
    "            print(leading + key + ': ' + str(item[key].shape))\n",
    "        else:\n",
    "            print(leading + key)\n",
    "            h5printR(item[key], leading + '  ')\n",
    "\n",
    "# Print structure of a `.h5` file            \n",
    "def h5print(filename):\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        print(filename)\n",
    "        h5printR(h, '  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/Projects/XRF_machine_learning/data/ISE_500sqaures_A21_054_botom_right_map_center_001.h5\n",
      "  xrmmap\n",
      "    areas\n",
      "      A21-054_Br_Xanes_spot: (201, 201)\n",
      "      A21-054_Br_Xanes_spot_2: (201, 201)\n",
      "      A21-054_I_Xanes_spot: (201, 201)\n",
      "      A21-054_I_Xanes_spot_2: (201, 201)\n",
      "      area_003: (201, 201)\n",
      "      area_004: (201, 201)\n",
      "    config\n",
      "      environ\n",
      "        address: (65,)\n",
      "        name: (65,)\n",
      "        value: (65,)\n",
      "      general\n",
      "        basedir: ()\n",
      "        envfile: ()\n",
      "      mca_calib\n",
      "        offset: (7,)\n",
      "        quad: (7,)\n",
      "        slope: (7,)\n",
      "      mca_settings\n",
      "      motor_controller\n",
      "        group: ()\n",
      "        host: ()\n",
      "        mode: ()\n",
      "        passwd: ()\n",
      "        positioners: ()\n",
      "        type: ()\n",
      "        user: ()\n",
      "      notes\n",
      "      positioners\n",
      "        13IDE:En:Energy: ()\n",
      "        13IDE:m19: ()\n",
      "        13IDE:m25: ()\n",
      "        13IDE:m28: ()\n",
      "        13IDE:m31: ()\n",
      "        13IDE:m32: ()\n",
      "        13IDE:m34: ()\n",
      "        13IDE:m35: ()\n",
      "        13IDE:m36: ()\n",
      "        13IDE:m39: ()\n",
      "        13IDE:m4: ()\n",
      "        13IDE:m40: ()\n",
      "        13IDE:userTran5.A: ()\n",
      "        13XRM:ANA:Energy: ()\n",
      "        13XRM:m1: ()\n",
      "        13XRM:m10: ()\n",
      "        13XRM:m11: ()\n",
      "        13XRM:m2: ()\n",
      "        13XRM:m3: ()\n",
      "        13XRM:m4: ()\n",
      "        13XRM:m5: ()\n",
      "        13XRM:m6: ()\n",
      "      rois\n",
      "        address: (35,)\n",
      "        limits: (35, 7, 2)\n",
      "        name: (35,)\n",
      "      scan\n",
      "        comments: ()\n",
      "        dimension: ()\n",
      "        filename: ()\n",
      "        pos1: ()\n",
      "        pos2: ()\n",
      "        start1: ()\n",
      "        start2: ()\n",
      "        step1: ()\n",
      "        step2: ()\n",
      "        stop1: ()\n",
      "        stop2: ()\n",
      "        text: ()\n",
      "        time1: ()\n",
      "    mcasum\n",
      "      counts: (201, 201, 4096)\n",
      "      dtfactor: (201, 201)\n",
      "      energy: (4096,)\n",
      "      inpcounts: (201, 201)\n",
      "      livetime: (201, 201)\n",
      "      outcounts: (201, 201)\n",
      "      realtime: (201, 201)\n",
      "    positions\n",
      "      address: (4,)\n",
      "      name: (4,)\n",
      "      pos: (201, 201, 4)\n",
      "    roimap\n",
      "      det_address: (253,)\n",
      "      det_cor: (201, 201, 253)\n",
      "      det_name: (253,)\n",
      "      det_raw: (201, 201, 253)\n",
      "      mcasum\n",
      "        As Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ba La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Br Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ca Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ce La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cl Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Co Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Cu Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Eu La\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Fe Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ge Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        I La1\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        I Lb1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        K Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Mn Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Mo Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ni Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        OutputCounts\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        P Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Pb La1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Rb Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Re La1\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        S Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Sc Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Se Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Si Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Sr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Ti Ka\n",
      "          cor: (201, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        V Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        V Kb\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Y Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zn Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zr Ka\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "        Zr L\n",
      "          cor: (1, 201)\n",
      "          limits: (2,)\n",
      "          raw: (1, 201)\n",
      "      sum_cor: (201, 201, 43)\n",
      "      sum_list: (43, 7)\n",
      "      sum_name: (43,)\n",
      "      sum_raw: (201, 201, 43)\n",
      "    scalars\n",
      "      I0: (201, 201)\n",
      "      I0_raw: (201, 201)\n",
      "      I1: (201, 201)\n",
      "      I1_raw: (201, 201)\n",
      "      I2: (201, 201)\n",
      "      I2_raw: (201, 201)\n",
      "      TSCALER: (201, 201)\n",
      "      TSCALER_raw: (201, 201)\n",
      "    work\n",
      "    xrd1d\n"
     ]
    }
   ],
   "source": [
    "xrf_data = h5py.File('/Users/user/Documents/Projects/XRF_machine_learning/data/ISE_500sqaures_A21_054_botom_right_map_center_001.h5','r')\n",
    "h5print('/Users/user/Documents/Projects/XRF_machine_learning/data/ISE_500sqaures_A21_054_botom_right_map_center_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 201, 4096)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigates h5 file\n",
    "#row_1 = xrf_data['xrmmap']['mcasum']['counts']\n",
    "#row_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical parameters\n",
    "\n",
    "these are needed to scale the data and pixelscorrectly etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in xrf_data['xrmmap']['mcasum']['counts'].attrs:\n",
    "    print(att,xrf_data['xrmmap']['mcasum']['counts'].attrs[att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 201, 4096)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrf_data['xrmmap']['mcasum']['counts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 201 4096\n"
     ]
    }
   ],
   "source": [
    "pix_x, pix_y, num_ch = xrf_data['xrmmap']['mcasum']['counts'].shape\n",
    "\n",
    "print(pix_x, pix_y, num_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "pix_x_size= pix_x - 1\n",
    "\n",
    "pix_y_size= pix_x - 1\n",
    "\n",
    "print(pix_x_size,pix_y_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map and axes management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table, th, td {\n",
       "\tborder: 1px solid black;\n",
       "\tborder-collapse: collapse;\n",
       "}\n",
       "th, td {\n",
       "\tpadding: 5px;\n",
       "}\n",
       "</style>\n",
       "<p><b>< Axes manager, axes: (201, 201|4096) ></b></p>\n",
       "<table style='width:100%'>\n",
       "\n",
       "<tr> \n",
       "<th>Navigation axis name</th> \n",
       "<th>size</th> \n",
       "<th>index</th> \n",
       "<th>offset</th> \n",
       "<th>scale</th> \n",
       "<th>units</th> </tr>\n",
       "<tr> \n",
       "<td><undefined></td> \n",
       "<td>201</td> \n",
       "<td>0</td> \n",
       "<td>0.0</td> \n",
       "<td>1.0</td> \n",
       "<td><undefined></td> </tr>\n",
       "<tr> \n",
       "<td><undefined></td> \n",
       "<td>201</td> \n",
       "<td>0</td> \n",
       "<td>0.0</td> \n",
       "<td>1.0</td> \n",
       "<td><undefined></td> </tr></table>\n",
       "<table style='width:100%'>\n",
       "\n",
       "<tr> \n",
       "<th>Signal axis name</th> \n",
       "<th>size</th> \n",
       "<th></th> \n",
       "<th>offset</th> \n",
       "<th>scale</th> \n",
       "<th>units</th> </tr>\n",
       "<tr> \n",
       "<td><undefined></td> \n",
       "<td>4096</td> \n",
       "<td></td> \n",
       "<td>0.0</td> \n",
       "<td>1.0</td> \n",
       "<td><undefined></td> </tr></table>\n"
      ],
      "text/plain": [
       "<Axes manager, axes: (201, 201|4096)>\n",
       "            Name |   size |  index |  offset |   scale |  units \n",
       "================ | ====== | ====== | ======= | ======= | ====== \n",
       "     <undefined> |    201 |      0 |       0 |       1 | <undefined> \n",
       "     <undefined> |    201 |      0 |       0 |       1 | <undefined> \n",
       "---------------- | ------ | ------ | ------- | ------- | ------ \n",
       "     <undefined> |   4096 |      0 |       0 |       1 | <undefined> "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrf_map = hs.signals.Signal1D(xrf_data['xrmmap']['mcasum']['counts'])\n",
    "xrf_map\n",
    "xrf_map.axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m dict1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m} \u001b[38;5;66;03m# y axis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dict2 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m300\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m} \u001b[38;5;66;03m# energy axis\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m xrf_map \u001b[38;5;241m=\u001b[39m hs\u001b[38;5;241m.\u001b[39msignals\u001b[38;5;241m.\u001b[39mSignal1D(xrf_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxrmmap\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcasum\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m], axes \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdict0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdict1\u001b[49m\u001b[43m]\u001b[49m[dict2])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#xrf_map.crop(axis=0,start=1)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#xrf_map.axes_manager[0].name = 'X'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#xrf_map.axes_manager['X'].units = '\\u03BCm'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#xrf_map = hs.signals.Signal1D(xrf_data['xrmmap']['mcasum']['counts'], axes = xrf_map.axes_manager)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not dict"
     ]
    }
   ],
   "source": [
    "dict0 = {'name': 'X', 'offset': 1, 'scale': 1, 'size': 500} # x axis\n",
    "dict1 = {'name': 'Y', 'offset': 1, 'scale': 1, 'size': 500} # y axis\n",
    "dict2 = {'name': 'energy', 'offset': 300, 'scale': 1, 'size': 500} # energy axis\n",
    "\n",
    "xrf_map = hs.signals.Signal1D(xrf_data['xrmmap']['mcasum']['counts'], axes = [dict0][dict1][dict2])\n",
    "\n",
    "\n",
    "#xrf_map.crop(axis=0,start=1)\n",
    "#xrf_map.axes_manager[0].name = 'X'\n",
    "#xrf_map.axes_manager['X'].units = '\\u03BCm'\n",
    "\n",
    "#xrf_map.crop(axis=1,start=1)\n",
    "#xrf_map.axes_manager[1].name = 'Y'\n",
    "#xrf_map.axes_manager['X'].units = '\\u03BCm'\n",
    "\n",
    "#xrf_map.axes_manager[2].name= 'Energy'\n",
    "#xrf_map.axes_manager['Energy'].units = 'kev'\n",
    "\n",
    "#xrf_map = hs.signals.Signal1D(xrf_data['xrmmap']['mcasum']['counts'], axes = xrf_map.axes_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='/Users/user/Documents/Projects/XRF_machine_learning/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite '/Users/user/Documents/Projects/XRF_machine_learning/data/map.hspy' (y/n)?\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "xrf_map.save(save_path+'map'.format(map))\n",
    "xrf_map.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions of the map\n",
    "also sets save paths..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_map.change_dtype('float32')\n",
    "xrf_map.save(save_path+'map1')\n",
    "\n",
    "xrf_stack = xrf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signal1D, title: , dimensions: (201, 201|4096)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrf_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrite '/Users/joshuashea/melt_mapsat16_map2_002_mapped_crop.hspy' (y/n)?\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "xrf_stack.change_dtype('float32')\n",
    "\n",
    "\n",
    "xrf_stack.save(save_path+'at16_map2_002_mapped_crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition info:\n",
      "  normalize_poissonian_noise=False\n",
      "  algorithm=sklearn_pca\n",
      "  output_dimension=20\n",
      "  centre=None\n",
      "scikit-learn estimator:\n",
      "PCA(n_components=20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9140697e088f463ab25ad59cf06521c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "xrf_stack.decomposition(normalize_poissonian_noise=False, algorithm=\"sklearn_pca\", output_dimension=20)\n",
    "\n",
    "xrf_stack.plot_explained_variance_ratio(log=True, vline=True)\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Principal component', ylabel='Cumulative explained variance ratio'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrf_stack.plot_cumulative_explained_variance_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note** iterative cropping above showed that most data/ analysis was better when cropping down to the shape (157, 63|2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.save(save_path+'lisheen_low_res_map_data_Crop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-explore\n",
    "\n",
    "get 6 good factors... need to label peaks etc but starting to pull out data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuashea/xraylarch/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition info:\n",
      "  normalize_poissonian_noise=False\n",
      "  algorithm=NMF\n",
      "  output_dimension=5\n",
      "  centre=None\n",
      "scikit-learn estimator:\n",
      "NMF(n_components=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuashea/xraylarch/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdb581e536645a5b27c857af180b408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xrf_stack.decomposition(normalize_poissonian_noise=False, algorithm='NMF', output_dimension=5)\n",
    "\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_stack.decomposition(normalize_poissonian_noise=True, algorithm='NMF', output_dimension=5)\n",
    "\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examine with factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition info:\n",
      "  normalize_poissonian_noise=False\n",
      "  algorithm=Pipeline(steps=[('FA', FactorAnalysis(n_components=5, rotation='varimax'))])\n",
      "  output_dimension=11\n",
      "  centre=None\n",
      "scikit-learn estimator:\n",
      "Pipeline(steps=[('FA', FactorAnalysis(n_components=5, rotation='varimax'))])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4941caacdc514b1db784b6f60801988a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"FA\", FactorAnalysis(n_components=5,rotation = 'varimax'))])\n",
    "\n",
    "xrf_stack.decomposition(normalize_poissonian_noise=False, algorithm=pipeline, return_info=True,output_dimension=11)\n",
    "\n",
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f918a03ee3b48ec9d699df9af545e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xrf_stack.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_load= xrf_stack.get_decomposition_loadings()\n",
    "#fa_load.save('snv_eds_analysis/plage_TD_eds_FA_4_load')\n",
    "\n",
    "fa_fact= xrf_stack.get_decomposition_factors()\n",
    "#fa_fact.set_elements(elements)\n",
    "\n",
    "\n",
    "#fa_fact.save('snv_eds_analysis/plage_TD_eds_FA_4_fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_facts, ydim,xdim=fa_load.data.shape\n",
    "\n",
    "fact_load_vect= pd.DataFrame((fa_load.data.reshape(fa_facts, ydim*xdim).T), columns = ['Factor 1','Factor 2','Factor 3','Factor 4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fact_load_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfact_load_vect\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fact_load_vect' is not defined"
     ]
    }
   ],
   "source": [
    "fact_load_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_facts, ydim,xdim=fa_load.data.shape\n",
    "fa_vect=fa_load.data.reshape(fa_facts,ydim*xdim).transpose()\n",
    "fa_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_to_cluster=fa_vect[:,:fa_facts]\n",
    "loadings_to_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGK(Probabilistic, GustafsonKesselMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clus=10\n",
    "pgk = PGK(n_clusters =num_clus, n_init=10).fit(loadings_to_cluster)\n",
    "# Process results for visualisation\n",
    "print(pgk.memberships_)\n",
    "labels_ = np.argmax(pgk.memberships_, axis=1)\n",
    "memberships_ = pgk.memberships_[range(len(pgk.memberships_)), labels_] \n",
    "\n",
    "labels = labels_.reshape([ydim,xdim])\n",
    "labels=hs.signals.Signal2D(labels)\n",
    "labels.plot(cmap='tab10')\n",
    "\n",
    "mems=pgk.memberships_.reshape(ydim,xdim,num_clus)\n",
    "print(mems.shape)\n",
    "\n",
    "mem_maps=hs.signals.Signal2D(mems)\n",
    "mem_maps=mem_maps.transpose(signal_axes=(2,0))\n",
    "mem_maps.change_dtype('float32')\n",
    "mem_maps.plot(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "mem_maps.plot(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next steps\n",
    "\n",
    "1. makes sense to calcualte an elbow test or examine the BIC to determine the 'optimal' number of clusters\n",
    "2. explore applying HDBSCAN on the FA/ PCA factors\n",
    "3. would also to explore the UMAP pretreatment then HDBSCAN\n",
    "4. maybe blind source separation (ie ICA) after PCA.\n",
    "\n",
    "for 2 and 3 need a different virtual enviroment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
